{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Whisper model ('base')...\n",
      "Model loaded successfully.\n",
      "\n",
      "Ground Truth: THE BIRCH CANOE SLID ON THE SMOOTH PLANKS\n",
      "\n",
      "--- ANALYSIS FOR: Baseline (Original Noisy Audio) ---\n",
      "Transcribing file: ../data/raw/car/5dB/sp01.wav\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load audio: ffmpeg version 2025-06-26-git-09cd38e9d5-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\r\n  built with gcc 15.1.0 (Rev4, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      60.  3.100 / 60.  3.100\r\n  libavcodec     62.  4.100 / 62.  4.100\r\n  libavformat    62.  1.100 / 62.  1.100\r\n  libavdevice    62.  0.100 / 62.  0.100\r\n  libavfilter    11.  0.100 / 11.  0.100\r\n  libswscale      9.  0.100 /  9.  0.100\r\n  libswresample   6.  0.100 /  6.  0.100\r\n[in#0 @ 0000020ce0b44380] Error opening input: No such file or directory\r\nError opening input file ../data/raw/car/5dB/sp01.wav.\r\nError opening input files: No such file or directory\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\DSP-Project\\keyword-asr-project\\venv\\Lib\\site-packages\\whisper\\audio.py:58\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(file, sr)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     out = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.stdout\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\subprocess.py:571\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    572\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', '../data/raw/car/5dB/sp01.wav', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 4294967294.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTranscribing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Transcribe the audio file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     whisper_output_raw = result[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m].strip()\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# Normalize the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\DSP-Project\\keyword-asr-project\\venv\\Lib\\site-packages\\whisper\\transcribe.py:139\u001b[39m, in \u001b[36mtranscribe\u001b[39m\u001b[34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[39m\n\u001b[32m    136\u001b[39m     decode_options[\u001b[33m\"\u001b[39m\u001b[33mfp16\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m mel = \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m content_frames = mel.shape[-\u001b[32m1\u001b[39m] - N_FRAMES\n\u001b[32m    141\u001b[39m content_duration = \u001b[38;5;28mfloat\u001b[39m(content_frames * HOP_LENGTH / SAMPLE_RATE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\DSP-Project\\keyword-asr-project\\venv\\Lib\\site-packages\\whisper\\audio.py:140\u001b[39m, in \u001b[36mlog_mel_spectrogram\u001b[39m\u001b[34m(audio, n_mels, padding, device)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.is_tensor(audio):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m         audio = \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     audio = torch.from_numpy(audio)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\DSP-Project\\keyword-asr-project\\venv\\Lib\\site-packages\\whisper\\audio.py:60\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(file, sr)\u001b[39m\n\u001b[32m     58\u001b[39m     out = run(cmd, capture_output=\u001b[38;5;28;01mTrue\u001b[39;00m, check=\u001b[38;5;28;01mTrue\u001b[39;00m).stdout\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.stderr.decode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.frombuffer(out, np.int16).flatten().astype(np.float32) / \u001b[32m32768.0\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to load audio: ffmpeg version 2025-06-26-git-09cd38e9d5-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\r\n  built with gcc 15.1.0 (Rev4, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      60.  3.100 / 60.  3.100\r\n  libavcodec     62.  4.100 / 62.  4.100\r\n  libavformat    62.  1.100 / 62.  1.100\r\n  libavdevice    62.  0.100 / 62.  0.100\r\n  libavfilter    11.  0.100 / 11.  0.100\r\n  libswscale      9.  0.100 /  9.  0.100\r\n  libswresample   6.  0.100 /  6.  0.100\r\n[in#0 @ 0000020ce0b44380] Error opening input: No such file or directory\r\nError opening input file ../data/raw/car/5dB/sp01.wav.\r\nError opening input files: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import jiwer\n",
    "import string\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# --- 1. Define the list of 30 ground truth sentences ---\n",
    "# This list is from the NOIZEUS corpus documentation.\n",
    "GROUND_TRUTH_SENTENCES = [\n",
    "    \"THE BIRCH CANOE SLID ON THE SMOOTH PLANKS\",\n",
    "    \"HE KNEW THE SKILL OF THE GREAT YOUNG ACTRESS\",\n",
    "    \"HER PURSE WAS FULL OF USELESS TRASH\",\n",
    "    \"READ VERSE OUT LOUD FOR PLEASURE\",\n",
    "    \"WIPE THE GREASE OFF HIS DIRTY FACE\",\n",
    "    \"MEN STRIVE BUT SELDOM GET RICH\",\n",
    "    \"WE FIND JOY IN THE SIMPLEST THINGS\",\n",
    "    \"HEDGE APPLES MAY STAIN YOUR HANDS GREEN\",\n",
    "    \"HURDLE THE PIT WITH THE AID OF A LONG POLE\",\n",
    "    \"THE SKY THAT MORNING WAS CLEAR AND BRIGHT BLUE\",\n",
    "    \"HE WROTE DOWN A LONG LIST OF ITEMS\",\n",
    "    \"THE DRIP OF THE RAIN MADE A PLEASANT SOUND\",\n",
    "    \"SMOKE POURED OUT OF EVERY CRACK\",\n",
    "    \"HATS ARE WORN TO TEA AND NOT TO DINNER\",\n",
    "    \"THE CLOTHES DRIED ON A THIN WOODEN RACK\",\n",
    "    \"THE STRAY CAT GAVE BIRTH TO KITTENS\",\n",
    "    \"THE LAZY COW LAY IN THE COOL GRASS\",\n",
    "    \"THE FRIENDLY GANG LEFT THE DRUG STORE\",\n",
    "    \"WE TALKED OF THE SIDESHOW IN THE CIRCUS\",\n",
    "    \"THE SET OF CHINA HIT THE FLOOR WITH A CRASH\",\n",
    "    \"CLAMS ARE SMALL, ROUND, SOFT AND TASTY\",\n",
    "    \"THE LINE WHERE THE EDGES JOIN WAS CLEAN\",\n",
    "    \"STOP WHISTLING AND WATCH THE BOYS MARCH\",\n",
    "    \"A CRUISE IN WARM WATERS IN A SLEEK YACHT IS FUN\",\n",
    "    \"A GOOD BOOK INFORMS OF WHAT WE OUGHT TO KNOW\",\n",
    "    \"SHE HAS A SMART WAY OF WEARING CLOTHES\",\n",
    "    \"BRING YOUR BEST COMPASS TO THE THIRD CLASS\",\n",
    "    \"THE CLUB RENTED THE RINK FOR THE FIFTH NIGHT\",\n",
    "    \"THE FLINT SPUTTERED AND LIT A PINE TORCH\",\n",
    "    \"LET'S ALL JOIN AS WE SING THE LAST CHORUS\"\n",
    "]\n",
    "\n",
    "# --- 2. Define the files and methods to test ---\n",
    "# This path assumes your notebook is in the `notebooks` folder.\n",
    "# Verify these filenames match what's in your `data/cleaned` and `data/raw` folders.\n",
    "FILES_TO_TEST = [\n",
    "    {\n",
    "        \"method_name\": \"Baseline (Original Noisy Audio)\",\n",
    "        \"path\": \"../data/raw/car/5dB/sp01_car_sn5.wav\"\n",
    "    },\n",
    "    {\n",
    "        \"method_name\": \"Spectral Subtraction\",\n",
    "        \"path\": \"../data/cleaned/sp01_ss_cleaned.wav\"\n",
    "    },\n",
    "    {\n",
    "        \"method_name\": \"Wiener Filter\",\n",
    "        \"path\": \"../data/cleaned/sp01_wf_cleaned.wav\"\n",
    "    },\n",
    "    {\n",
    "        \"method_name\": \"Hybrid Method\",\n",
    "        \"path\": \"../data/cleaned/sp01_hy_cleaned.wav\"\n",
    "    }\n",
    "]\n",
    "\n",
    "SENTENCE_INDEX = 0 # All 'sp01' files correspond to the first sentence (index 0)\n",
    "MODEL_SIZE = \"base\"\n",
    "\n",
    "# --- 3. Load the model (only once) ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(f\"Loading Whisper model ('{MODEL_SIZE}')...\")\n",
    "model = whisper.load_model(MODEL_SIZE, device=device)\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# --- 4. Define normalization function and get ground truth ---\n",
    "def normalize_text(text):\n",
    "    return text.upper().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "ground_truth_raw = GROUND_TRUTH_SENTENCES[SENTENCE_INDEX]\n",
    "ground_truth = normalize_text(ground_truth_raw)\n",
    "print(f\"\\nGround Truth: {ground_truth}\\n\")\n",
    "\n",
    "\n",
    "# --- 5. Loop through and test each file ---\n",
    "for test_case in FILES_TO_TEST:\n",
    "    method_name = test_case[\"method_name\"]\n",
    "    audio_path = test_case[\"path\"]\n",
    "    \n",
    "    print(f\"--- ANALYSIS FOR: {method_name} ---\")\n",
    "    print(f\"Transcribing file: {audio_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Transcribe the audio file\n",
    "        result = model.transcribe(audio_path)\n",
    "        whisper_output_raw = result[\"text\"].strip()\n",
    "        \n",
    "        # Normalize the output\n",
    "        whisper_output = normalize_text(whisper_output_raw)\n",
    "        \n",
    "        # Calculate WER\n",
    "        error = jiwer.wer(ground_truth, whisper_output)\n",
    "        \n",
    "        print(f\"Whisper Output: {whisper_output}\")\n",
    "        print(f\"Word Error Rate (WER): {error * 100:.2f}%\\n\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File not found at {audio_path}. Please check the path.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
